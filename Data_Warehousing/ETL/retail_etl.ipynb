{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f6bc1d",
   "metadata": {},
   "source": [
    "## ETL Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbad2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef2fd5",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7407978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path again\n",
    "data_path = r\"C:\\Users\\Admin\\OneDrive - United States International University (USIU)\\Documents\\USIU_A\\US2025\\DSA2040A\\Final Exam\\DSA_2040_Practical_Exam_Ambachow_550\\Data_Warehousing\\data\\online_retail.csv\"\n",
    "\n",
    "# Step 1: Extract - Read CSV\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f45315c",
   "metadata": {},
   "source": [
    "#### Columns/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dafc3fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID',\n",
      "       'Country'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Description  540455 non-null  object \n",
      " 1   Quantity     541909 non-null  int64  \n",
      " 2   InvoiceDate  541909 non-null  object \n",
      " 3   UnitPrice    541909 non-null  float64\n",
      " 4   CustomerID   406829 non-null  float64\n",
      " 5   Country      541909 non-null  object \n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 24.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3dfa3",
   "metadata": {},
   "source": [
    "### Wrangle function for Transformation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7461de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def etl_online_retail(\n",
    "    csv_path: str,\n",
    "    db_path: str,\n",
    "    filter_date: str = '2024-08-12'  # Default cutoff date for filtering sales last year\n",
    "):\n",
    "    \"\"\"\n",
    "    ETL process for Online Retail data.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): File path to the input CSV data.\n",
    "        db_path (str): SQLite database file path to load data.\n",
    "        filter_date (str): Filter sales from this date onward (YYYY-MM-DD).\n",
    "        \n",
    "    Returns:\n",
    "        None, but saves cleaned/transformed data into SQLite DB.\n",
    "    \"\"\"\n",
    "    print(\"Starting ETL process...\")\n",
    "    \n",
    "    # Transform\n",
    "    print(\"Transforming data...\")\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
    "    \n",
    "    # Remove rows with invalid Quantity or UnitPrice\n",
    "    original_count = df.shape[0]\n",
    "    df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
    "    filtered_count = df.shape[0]\n",
    "    print(f\"Removed {original_count - filtered_count} rows with invalid Quantity or UnitPrice\")\n",
    "    \n",
    "    # Calculate TotalSales\n",
    "    df['TotalSales'] = df['Quantity'] * df['UnitPrice']\n",
    "    \n",
    "    # Filter for sales from filter_date onward\n",
    "    cutoff_date = pd.Timestamp(filter_date)\n",
    "    df_filtered = df[df['InvoiceDate'] >= cutoff_date]\n",
    "    print(f\"Filtered data to {df_filtered.shape[0]} rows from {filter_date} onwards\")\n",
    "    \n",
    "    # Customer Dimension\n",
    "    print(\"Creating Customer Dimension...\")\n",
    "    customer_dim = df_filtered.groupby('CustomerID').agg(\n",
    "        TotalPurchases=('TotalSales', 'sum'),\n",
    "        Country=('Country', 'first')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Time Dimension\n",
    "    print(\"Creating Time Dimension...\")\n",
    "    time_dim = df_filtered[['InvoiceDate']].drop_duplicates().copy()\n",
    "    time_dim['Date'] = time_dim['InvoiceDate'].dt.date\n",
    "    time_dim['Year'] = time_dim['InvoiceDate'].dt.year\n",
    "    time_dim['Quarter'] = time_dim['InvoiceDate'].dt.quarter\n",
    "    time_dim['Month'] = time_dim['InvoiceDate'].dt.month\n",
    "    \n",
    "    # Sales Fact Table\n",
    "    print(\"Preparing Sales Fact Table...\")\n",
    "    sales_fact = df_filtered.merge(time_dim, on='InvoiceDate', how='left')\n",
    "    sales_fact_table = sales_fact[[\n",
    "        'InvoiceNo', 'CustomerID', 'StockCode', 'Quantity', 'UnitPrice', 'TotalSales',\n",
    "        'Date', 'Year', 'Quarter', 'Month'\n",
    "    ]]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b4bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "def etl_online_retail(csv_path, db_path, filter_date='2024-08-12'):\n",
    "    \"\"\"\n",
    "    ETL process for Online Retail data into a star schema SQLite database.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the raw CSV dataset.\n",
    "        db_path (str): Path to SQLite database file.\n",
    "        filter_date (str): Filter sales from this date onward (YYYY-MM-DD).\n",
    "\n",
    "    Returns:\n",
    "        None (creates and loads tables into SQLite DB)\n",
    "    \"\"\"\n",
    "    print(\"Starting ETL process...\")\n",
    "\n",
    "    # Extract\n",
    "    print(\"Loading raw data...\")\n",
    "    df = pd.read_csv(csv_path, encoding='ISO-8859-1')\n",
    "\n",
    "    # Basic cleaning and type conversions\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
    "    df = df.dropna(subset=['InvoiceDate', 'CustomerID', 'StockCode'])  # Remove rows missing critical keys\n",
    "    \n",
    "    # Remove invalid sales data\n",
    "    df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
    "\n",
    "    # Calculate TotalSales\n",
    "    df['TotalSales'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "    # Filter sales from filter_date onward\n",
    "    cutoff_date = pd.to_datetime(filter_date)\n",
    "    df = df[df['InvoiceDate'] >= cutoff_date]\n",
    "\n",
    "    # Create TimeDim table\n",
    "    print(\"Creating Time Dimension...\")\n",
    "    time_dim = df[['InvoiceDate']].drop_duplicates().copy()\n",
    "    time_dim['Date'] = time_dim['InvoiceDate'].dt.date\n",
    "    time_dim['Year'] = time_dim['InvoiceDate'].dt.year\n",
    "    time_dim['Quarter'] = time_dim['InvoiceDate'].dt.quarter\n",
    "    time_dim['Month'] = time_dim['InvoiceDate'].dt.month\n",
    "    time_dim['Day'] = time_dim['InvoiceDate'].dt.day\n",
    "    time_dim['TimeID'] = time_dim['InvoiceDate'].dt.strftime('%Y%m%d').astype(int)\n",
    "    time_dim = time_dim.drop(columns=['InvoiceDate'])\n",
    "    time_dim = time_dim.sort_values('Date')\n",
    "\n",
    "    # Create CustomerDim table\n",
    "    print(\"Creating Customer Dimension...\")\n",
    "    customer_dim = df.groupby('CustomerID').agg({\n",
    "        'Country': 'first',\n",
    "        'TotalSales': 'sum'\n",
    "    }).reset_index()\n",
    "    customer_dim.columns = ['CustomerID', 'Country', 'TotalPurchases']\n",
    "\n",
    "    # Create ProductDim table\n",
    "    print(\"Creating Product Dimension...\")\n",
    "    product_dim = df.groupby('StockCode').agg({\n",
    "        'Description': 'first'\n",
    "    }).reset_index()\n",
    "    # Optionally add Category, for now set as NULL or 'Unknown'\n",
    "    product_dim['Category'] = 'Unknown'\n",
    "\n",
    "    # Create SalesFact table\n",
    "    print(\"Creating Sales Fact Table...\")\n",
    "    # Map TimeID in fact table by joining on date\n",
    "    df['TimeID'] = df['InvoiceDate'].dt.strftime('%Y%m%d').astype(int)\n",
    "    sales_fact = df[['InvoiceNo', 'CustomerID', 'StockCode', 'Quantity', 'UnitPrice', 'TotalSales', 'TimeID']]\n",
    "\n",
    "    # Load to SQLite\n",
    "    print(f\"Loading data into SQLite DB at {db_path} ...\")\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # Create tables in DB\n",
    "    with conn:\n",
    "        # Drop tables if exist (for repeatability)\n",
    "        conn.execute(\"DROP TABLE IF EXISTS SalesFact\")\n",
    "        conn.execute(\"DROP TABLE IF EXISTS CustomerDim\")\n",
    "        conn.execute(\"DROP TABLE IF EXISTS ProductDim\")\n",
    "        conn.execute(\"DROP TABLE IF EXISTS TimeDim\")\n",
    "\n",
    "        # Create dimension tables\n",
    "        conn.execute(\"\"\"\n",
    "        CREATE TABLE CustomerDim (\n",
    "            CustomerID INTEGER PRIMARY KEY,\n",
    "            Country TEXT,\n",
    "            TotalPurchases REAL\n",
    "        )\n",
    "        \"\"\")\n",
    "        conn.execute(\"\"\"\n",
    "        CREATE TABLE ProductDim (\n",
    "            StockCode TEXT PRIMARY KEY,\n",
    "            Description TEXT,\n",
    "            Category TEXT\n",
    "        )\n",
    "        \"\"\")\n",
    "        conn.execute(\"\"\"\n",
    "        CREATE TABLE TimeDim (\n",
    "            TimeID INTEGER PRIMARY KEY,\n",
    "            Date DATE,\n",
    "            Year INTEGER,\n",
    "            Quarter INTEGER,\n",
    "            Month INTEGER,\n",
    "            Day INTEGER\n",
    "        )\n",
    "        \"\"\")\n",
    "        # Create fact table\n",
    "        conn.execute(\"\"\"\n",
    "        CREATE TABLE SalesFact (\n",
    "            SaleID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            InvoiceNo TEXT,\n",
    "            CustomerID INTEGER,\n",
    "            StockCode TEXT,\n",
    "            TimeID INTEGER,\n",
    "            Quantity INTEGER,\n",
    "            UnitPrice REAL,\n",
    "            TotalSales REAL,\n",
    "            FOREIGN KEY(CustomerID) REFERENCES CustomerDim(CustomerID),\n",
    "            FOREIGN KEY(StockCode) REFERENCES ProductDim(StockCode),\n",
    "            FOREIGN KEY(TimeID) REFERENCES TimeDim(TimeID)\n",
    "        )\n",
    "        \"\"\")\n",
    "\n",
    "    # Insert data into tables\n",
    "    customer_dim.to_sql('CustomerDim', conn, if_exists='append', index=False)\n",
    "    product_dim.to_sql('ProductDim', conn, if_exists='append', index=False)\n",
    "    time_dim.to_sql('TimeDim', conn, if_exists='append', index=False)\n",
    "    sales_fact.to_sql('SalesFact', conn, if_exists='append', index=False)\n",
    "\n",
    "    print(\"ETL process completed successfully!\")\n",
    "    conn.close()\n",
    "\n",
    "# Usage example:\n",
    "# etl_online_retail(\n",
    "#     csv_path=\"path/to/Online Retail.csv\",\n",
    "#     db_path=\"path/to/retail_dw.db\",\n",
    "#     filter_date=\"2024-08-12\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c753cd1",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cadf21e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data into database at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdb_path\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m conn \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(db_path)\n\u001b[0;32m      5\u001b[0m customer_dim\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerDim\u001b[39m\u001b[38;5;124m'\u001b[39m, conn, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'db_path' is not defined"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "print(f\"Loading data into database at: {db_path}\")\n",
    "conn = sqlite3.connect(db_path)\n",
    "    \n",
    "customer_dim.to_sql('CustomerDim', conn, if_exists='replace', index=False)\n",
    "time_dim.to_sql('TimeDim', conn, if_exists='replace', index=False)\n",
    "sales_fact_table.to_sql('SalesFact', conn, if_exists='replace', index=False)\n",
    "    \n",
    "conn.close()\n",
    "print(\"ETL process completed successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb0de14",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e424140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "csv_path = r\"C:\\Users\\Admin\\OneDrive - United States International University (USIU)\\Documents\\USIU_A\\US2025\\DSA2040A\\Final Exam\\DSA_2040_Practical_Exam_Ambachow_550\\Data_Warehousing\\data\\online_retail.csv\"\n",
    "db_path = r\"C:\\Users\\Admin\\OneDrive - United States International University (USIU)\\Documents\\USIU_A\\US2025\\DSA2040A\\Final Exam\\DSA_2040_Practical_Exam_Ambachow_550\\Data_Warehousing\\data\\retail_dw.db\"\n",
    "\n",
    "etl_online_retail(csv_path, db_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
